#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Tue Aug  8 11:10:34 2017

@author: mahyar khayatkhoei
"""

import numpy as np
import tensorflow as tf
import os

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" # so the IDs match nvidia-smi
os.environ["CUDA_VISIBLE_DEVICES"] = "1" # "0, 1" for multiple

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import os
from progressbar import ETA, Bar, Percentage, ProgressBar
from mpl_toolkits.mplot3d.axes3d import Axes3D, get_test_data
from matplotlib import cm
import matplotlib.tri as mtri
import argparse
print matplotlib.get_backend()
import scipy.stats as sc_stats
import matplotlib.cm as mat_cm
import cPickle as pk

arg_parser = argparse.ArgumentParser()
arg_parser.add_argument('-l', '--log-path', dest='log_path', required=True, help='log directory to store logs.')
arg_parser.add_argument('-e', '--eval', dest='eval_int', required=True, help='eval intervals.')
arg_parser.add_argument('-s', '--seed', dest='seed', default=0, help='random seed.')
args = arg_parser.parse_args()
log_path = args.log_path
eval_int = int(args.eval_int)
run_seed = int(args.seed)

np.random.seed(run_seed)
tf.set_random_seed(run_seed)

import tf_dmgan

log_path_snap = log_path+'/snapshots'
log_path_data = log_path+'/log_data'
log_path_sum = log_path+'/log_sum'
os.system('mkdir -p '+log_path_snap)
os.system('mkdir -p '+log_path_data)
os.system('mkdir -p '+log_path_sum)

def generate_circle_data(data_size):
	num_comp = 2
	z = np.random.uniform(0.0, 2*np.pi, data_size)
	ch = np.random.choice(num_comp, size=data_size, replace=True, p=[0.5, 0.5])
	
	x1 = np.sin(z) - 2
	y1 = np.cos(z)

	x2 = np.sin(z) + 2
	y2 = np.cos(z)

	dx = np.c_[x1, x2]
	dy = np.c_[y1, y2]

	data = np.c_[dx[np.arange(data_size), ch], dy[np.arange(data_size), ch]]
	return data

def generate_line_data(data_size):
	num_lines = 4
	lb = 0.
	ub = 1.
	z = np.random.uniform(lb, ub, data_size)
	ch = np.random.choice(num_lines, size=data_size, replace=True, p=[0.25, 0.25, 0.25, 0.25])
	
	x1 = z * .25 + (1-z) * .75
	y1 = -1. * x1 + 1.
	
	x2 = -x1 
	y2 = -1. * x2 - 1.

	x3 = x1
	y3 = 1. * x3 - 1.

	x4 = -x1
	y4 = 1. * x4 + 1.

	dx = np.c_[x1, x2, x3, x4]
	dy = np.c_[y1, y2, y3, y4]
	data = np.c_[dx[np.arange(data_size), ch], dy[np.arange(data_size), ch]]
	return data

'''
Scatter plot the datasets.
datasets: list of data_size*data_dim arrays to be plotted.
color: rgba color list corresponding to datasets
pathname: image filename.
'''
def plot_dataset(datasets, color, pathname, title='Dataset', fov=2):
	### plot the dataset
	fig, ax = plt.subplots(figsize=(8, 6))
	ax.clear()
	#plt.scatter(dataset[:,0], dataset[:,1], c=gt.astype(int))

	for i, d in enumerate(datasets):
		d = d.reshape([d.size, 1]) if len(d.shape) == 1 else d
		if d.shape[-1] == 1:
			d = np.c_[d, np.ones(d.shape)]
		ax.scatter(d[:,0], d[:,1], c=color[i], marker='.', edgecolors='none')
	ax.set_title(title)
	ax.set_xlim(-fov, fov)
	ax.set_ylim(-fov, fov)
	ax.grid(True, which='both', linestyle='dotted')
	fig.savefig(pathname, dpi=300)
	plt.close(fig)

'''
Plot the data generated by dmgan, colored by each generator id.
pathname: image filename.
'''
def plot_dataset_gid(dmgan, data_size, color_map, pathname, fov=2):
	g_num = dmgan.g_num
	cmap = mat_cm.get_cmap(color_map)
	rgb_colors = cmap(1.0 * np.arange(dmgan.g_num) / (dmgan.g_num-1))
	rgb_colors[:,3] = 1.
	g_data = list()
	for i in range(g_num):
		z = i * np.ones(data_size)
		g_data.append(sample_dmgan(dmgan, data_size, z_data=z))
		g_color = np.array(rgb_colors[i,:].reshape(1, 4))
		g_color[:,3] = 1.
		#plot_dataset([g_data[-1]], g_color, pathname+'_gid_'+str(i)+'.png', 'gid_'+str(i), fov=fov)
	plot_dataset(g_data, rgb_colors.reshape(-1, 4), pathname+'_gids.png', 'Generators', fov=fov)

'''
Plot the data generated by dmgan, colored by the encoder of dmgan.
pathname: image filename.
'''
def plot_dataset_en(dmgan, dataset, color_map, pathname, title='Dataset', fov=2, color_bar=True):
	### plot the dataset
	fig, ax = plt.subplots(figsize=(8, 6))
	ax.clear()

	d = dataset.reshape([dataset.size, 1]) if len(dataset.shape) == 1 else dataset
	en_logits = eval_dmgan_en(dmgan, d)
	cid = np.argmax(en_logits, axis=1)
	if d.shape[-1] == 1:
		d = np.c_[d, np.ones(d.shape)]
	dec = ax.scatter(d[:,0], d[:,1], c=cid, cmap=color_map, 
		marker='.', edgecolors='none', vmin=0, vmax=dmgan.g_num-1)

	if color_bar is True:
		fig.colorbar(dec)
	ax.set_title(title)
	ax.set_xlim(-fov, fov)
	ax.set_ylim(-fov, fov)
	ax.grid(True, which='both', linestyle='dotted')
	fig.savefig(pathname, dpi=300)
	plt.close(fig)

def plot_time_series(name, vals, fignum, save_path, color='b', ytype='linear', itrs=None):
	fig, ax = plt.subplots(figsize=(8, 6))
	ax.clear()
	if itrs is None:
		ax.plot(vals, color=color)	
	else:
		ax.plot(itrs, vals, color=color)
	ax.grid(True, which='both', linestyle='dotted')
	ax.set_title(name)
	ax.set_xlabel('Iterations')
	ax.set_ylabel('Values')
	if ytype=='log':
		ax.set_yscale('log')
	fig.savefig(save_path, dpi=300)
	plt.close(fig)

def plot_time_mat(mat, mat_names, fignum, save_path, ytype=None, itrs=None):
	for n in range(mat.shape[1]):
		fig_name = mat_names[n]
		if not ytype:
			ytype = 'log' if 'param' in fig_name else 'linear'
		plot_time_series(fig_name, mat[:,n], fignum, save_path+'/'+fig_name+'.png', ytype=ytype, itrs=itrs)

'''
Sample sample_size data points from dmgan.
'''
def sample_dmgan(dmgan, sample_size, batch_size=512, z_data=None, zi_data=None):
	g_samples = np.zeros([sample_size, dmgan.data_dim])
	for batch_start in range(0, sample_size, batch_size):
		batch_end = batch_start + batch_size
		batch_len = g_samples[batch_start:batch_end, ...].shape[0]
		batch_z = z_data[batch_start:batch_end, ...] if z_data is not None else None
		batch_zi = zi_data[batch_start:batch_end, ...] if zi_data is not None else None
		g_samples[batch_start:batch_end, ...] = \
			dmgan.step(None, batch_len, gen_only=True, z_data=batch_z, zi_data=batch_zi)
	return g_samples

'''
Evaluate encoder logits on the given dataset.
'''
def eval_dmgan_en(dmgan, im_data, batch_size=512):
	sample_size = im_data.shape[0]
	en_logits = np.zeros([sample_size, dmgan.g_num])
	for batch_start in range(0, sample_size, batch_size):
		batch_end = batch_start + batch_size
		batch_im = im_data[batch_start:batch_end, ...]
		en_logits[batch_start:batch_end, ...] = \
			dmgan.step(batch_im, None, en_only=True)
	return en_logits

'''
Compute the accuracy of encoder network over generator ids.
'''
def eval_dataset_en(dmgan, im_data, im_lable, batch_size=512):
	en_logits = eval_dmgan_en(dmgan, im_data, batch_size)
	acc = np.mean((np.argmax(en_logits, axis=1) - im_lable) == 0)
	return acc

'''
Training DMGAN
'''
def train_dmgan(dmgan, data_sampler):
	### dataset definition
	data_dim = dmgan.data_dim
	train_size = 50000

	### drawing configs
	d_draw = 0
	g_draw = 0

	### training configs
	max_itr_total = 5e5
	g_max_itr = 2e4
	d_updates = 5
	g_updates = 1
	batch_size = 32
	eval_step = eval_int

	### logs initi
	eval_logs = list()
	stats_logs = list()
	itrs_logs = list()
	rl_vals_logs = list()
	rl_pvals_logs = list()

	### training inits
	d_itr = 0
	g_itr = 0
	itr_total = 0
	epoch = 0
	d_update_flag = True if d_updates > 0 else False
	widgets = ["dmgan", Percentage(), Bar(), ETA()]
	pbar = ProgressBar(maxval=max_itr_total, widgets=widgets)
	pbar.start()
	train_dataset = data_sampler(train_size).reshape([-1, data_dim])

	while itr_total < max_itr_total:
		### get samples from dataset 
		np.random.shuffle(train_dataset)
		epoch += 1
		print ">>> Epoch %d started..." % epoch
		### train one epoch
		for batch_start in range(0, train_size, batch_size):
			if itr_total >= max_itr_total:
				break
			pbar.update(itr_total)
			batch_end = batch_start + batch_size
			### fetch batch data
			batch_data = train_dataset[batch_start:batch_end, :]
			fetch_batch = False
			while fetch_batch is False:
				### evaluate energy distance between real and gen distributions
				if itr_total % eval_step == 0:
					e_dist, e_norm, net_stats = eval_dmgan(dmgan, data_sampler, itr_total)
					e_dist = 0 if e_dist < 0 else np.sqrt(e_dist)
					eval_logs.append([e_dist, e_dist/np.sqrt(2.0*e_norm)])
					stats_logs.append(net_stats)
					itrs_logs.append(itr_total)
					rl_vals_logs.append(list(dmgan.g_rl_vals))
					z_pr = np.exp(dmgan.pg_temp * dmgan.g_rl_pvals)
					z_pr = z_pr / np.sum(z_pr)
					rl_pvals_logs.append(list(z_pr))

				### discriminator update
				if d_update_flag is True:
					batch_sum, batch_g_data = dmgan.step(batch_data, batch_size=None, gen_update=False)
					dmgan.write_sum(batch_sum, itr_total)
					d_itr += 1
					itr_total += 1
					d_update_flag = False if d_itr % d_updates == 0 else True
					fetch_batch = True
				
				### generator updates: g_updates times for each d_updates of discriminator
				elif g_updates > 0:
					batch_sum, batch_g_data = dmgan.step(batch_data, batch_size=None, gen_update=True)
					dmgan.write_sum(batch_sum, itr_total)
					g_itr += 1
					itr_total += 1
					d_update_flag = True if g_itr % g_updates == 0 else False
				
				if itr_total >= max_itr_total:
					break

		dmgan.save(log_path_snap+'/model_%d_%d.h5' % (g_itr, itr_total))

		### plot dmgan gan progress logs
		if len(eval_logs) < 2:
			continue
		eval_logs_mat = np.array(eval_logs)
		stats_logs_mat = np.array(stats_logs)
		rl_vals_logs_mat = np.array(rl_vals_logs)
		rl_pvals_logs_mat = np.array(rl_pvals_logs)

		eval_logs_names = ['energy_distance', 'energy_distance_norm']
		stats_logs_names = ['nan_vars', 'inf_vars', 'tiny_vars_ratio', 
							'big_vars_ratio']

		plot_time_mat(eval_logs_mat, eval_logs_names, 1, log_path, itrs=itrs_logs)
		plot_time_mat(stats_logs_mat, stats_logs_names, 1, log_path, itrs=itrs_logs)

		### plot rl_vals
		fig, ax = plt.subplots(figsize=(8, 6))
		ax.clear()
		for g in range(dmgan.g_num):
			ax.plot(itrs_logs, rl_vals_logs_mat[:, g], label='g_%d' % g)
		ax.grid(True, which='both', linestyle='dotted')
		ax.set_title('Empirical Prior Values')
		ax.set_xlabel('Iterations')
		ax.set_ylabel('Values')
		#ax.legend(loc=0)
		fig.savefig(log_path+'/emp_prior_vals.png', dpi=300)
		plt.close(fig)
		
		### plot rl_pvals
		pr_g = np.exp(rl_pvals_logs_mat)
		pr_g = pr_g / (np.sum(pr_g, axis=1).reshape([-1, 1]))
		pvals_mat = pr_g

		fig, ax = plt.subplots(figsize=(8, 6))
		ax.clear()
		for g in range(dmgan.g_num):
			ax.plot(itrs_logs, pvals_mat[:, g], label='g_%d' % g)
		ax.grid(True, which='both', linestyle='dotted')
		ax.set_title('Prior Learning')
		ax.set_xlabel('Iterations')
		ax.set_ylabel('Values')
		#ax.legend(loc=0)
		fig.savefig(log_path+'/prior_learning.png', dpi=300)
		plt.close(fig)

		### save pval_logs
		with open(log_path+'/pvals.cpk', 'wb+') as fs:
			pk.dump([itrs_logs, rl_pvals_logs_mat], fs)

def eval_dmgan(dmgan, data_sampler, itr):
	### dataset definition
	data_dim = dmgan.data_dim
	sample_size = 10000
	r_samples = data_sampler(sample_size)
	g_samples = sample_dmgan(dmgan, sample_size)
	if data_dim > 1:
		rr_score = np.mean(np.sqrt(np.sum(np.square(r_samples[0:sample_size//2, ...] - r_samples[sample_size//2:, ...]), axis=1)))
		gg_score = np.mean(np.sqrt(np.sum(np.square(g_samples[0:sample_size//2, ...] - g_samples[sample_size//2:, ...]), axis=1)))
		rg_score = np.mean(np.sqrt(np.sum(np.square(r_samples[0:sample_size//2, ...] - g_samples[0:sample_size//2, ...]), axis=1)))
	else:
		rr_score = np.mean(np.abs(r_samples[0:sample_size//2] - r_samples[sample_size//2:]))
		gg_score = np.mean(np.abs(g_samples[0:sample_size//2] - g_samples[sample_size//2:]))
		rg_score = np.mean(np.abs(r_samples[0:sample_size//2] - g_samples[0:sample_size//2]))

	### get network stats
	net_stats = dmgan.step(None, None, stats_only=True)

	### draw samples
	data_r = r_samples
	data_g = g_samples
	#plot_dataset_en(dmgan, data_r, color_map='tab10', pathname=log_path_data+'/data_%06d_r.png' % itr, color_bar=False)
	plot_dataset_en(dmgan, data_g, color_map='tab10', pathname=log_path_data+'/data_%06d_gen.png' % itr, color_bar=False)
	plot_dataset_gid(dmgan, sample_size, color_map='tab10', pathname=log_path_data+'/data_%06d' % itr)

	return 2*rg_score - rr_score - gg_score, rg_score, net_stats


if __name__ == '__main__':
	'''
	DATASET MAKING
	'''
	centers = [[-1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, -1.0]]
	stds = [[0.02, 0.02], [0.02, 0.02], [0.02, 0.02], [0.02, 0.02]]
	#ratios = [0.2, 0.2, 0.4, 0.2]
	ratios = None
	data_dim = 2

	### function with data_size input that generates randomized training data
	data_sampler = generate_line_data
	#data_sampler = generate_circle_data
	data_r = data_sampler(50000)
	plot_dataset([data_r], color=['r'], pathname=log_path+'/real_dataset.png')

	'''
	TENSORFLOW SETUP
	'''
	gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)
	config = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)
	sess = tf.Session(config=config)
	
	### get a dmgan instance
	dmgan = tf_dmgan.DMGAN(sess, data_dim, log_path_sum)
	
	### init variables
	sess.run(tf.global_variables_initializer())

	'''
	GAN SETUP
	'''
	### train dmgan model
	train_dmgan(dmgan, data_sampler)

	### load dmgan model
	#dmgan.load(dmgan_path)

	### generate sample draw
	sample_size = 10000
	data_g = sample_dmgan(dmgan, sample_size)
	data_r = data_sampler(sample_size)
	plot_dataset([data_r], color=['r'], pathname=log_path+'/real_dataset.png', fov=2)
	#plot_dataset([data_g], color=['b'], pathname=log_path+'/gen_dataset.png', fov=2)
	plot_dataset_en(dmgan, data_g, color_map='tab10', pathname=log_path+'/gen_dataset.png', fov=2, color_bar=False)




